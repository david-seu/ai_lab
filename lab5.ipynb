{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1408,  0.4293],\n",
      "        [-0.0117,  0.5344],\n",
      "        [ 0.1090,  0.2367],\n",
      "        [-0.0038,  0.5168]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/1000], Loss: 0.2863\n",
      "tensor([[0.1468, 0.4296],\n",
      "        [0.0064, 0.5322],\n",
      "        [0.1137, 0.2570],\n",
      "        [0.0154, 0.5113]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [2/1000], Loss: 0.2776\n",
      "tensor([[0.1517, 0.4328],\n",
      "        [0.0240, 0.5354],\n",
      "        [0.1188, 0.2768],\n",
      "        [0.0340, 0.5107]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [3/1000], Loss: 0.2697\n",
      "tensor([[0.1564, 0.4372],\n",
      "        [0.0411, 0.5406],\n",
      "        [0.1243, 0.2962],\n",
      "        [0.0519, 0.5119]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [4/1000], Loss: 0.2625\n",
      "tensor([[0.1611, 0.4417],\n",
      "        [0.0577, 0.5464],\n",
      "        [0.1301, 0.3151],\n",
      "        [0.0690, 0.5133]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [5/1000], Loss: 0.2558\n",
      "tensor([[0.1661, 0.4462],\n",
      "        [0.0737, 0.5523],\n",
      "        [0.1363, 0.3333],\n",
      "        [0.0853, 0.5146]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [6/1000], Loss: 0.2496\n",
      "tensor([[0.1711, 0.4507],\n",
      "        [0.0892, 0.5579],\n",
      "        [0.1427, 0.3509],\n",
      "        [0.1010, 0.5154]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [7/1000], Loss: 0.2439\n",
      "tensor([[0.1762, 0.4551],\n",
      "        [0.1041, 0.5632],\n",
      "        [0.1495, 0.3677],\n",
      "        [0.1159, 0.5157]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [8/1000], Loss: 0.2387\n",
      "tensor([[0.1814, 0.4594],\n",
      "        [0.1184, 0.5679],\n",
      "        [0.1565, 0.3837],\n",
      "        [0.1301, 0.5152]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [9/1000], Loss: 0.2339\n",
      "tensor([[0.1867, 0.4635],\n",
      "        [0.1322, 0.5721],\n",
      "        [0.1638, 0.3988],\n",
      "        [0.1436, 0.5140]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [10/1000], Loss: 0.2295\n",
      "tensor([[0.1919, 0.4672],\n",
      "        [0.1453, 0.5757],\n",
      "        [0.1713, 0.4130],\n",
      "        [0.1563, 0.5119]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [11/1000], Loss: 0.2255\n",
      "tensor([[0.1972, 0.4706],\n",
      "        [0.1577, 0.5785],\n",
      "        [0.1789, 0.4262],\n",
      "        [0.1683, 0.5089]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [12/1000], Loss: 0.2219\n",
      "tensor([[0.2024, 0.4736],\n",
      "        [0.1695, 0.5806],\n",
      "        [0.1867, 0.4384],\n",
      "        [0.1796, 0.5049]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [13/1000], Loss: 0.2185\n",
      "tensor([[0.2076, 0.4761],\n",
      "        [0.1807, 0.5819],\n",
      "        [0.1945, 0.4496],\n",
      "        [0.1901, 0.4999]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [14/1000], Loss: 0.2155\n",
      "tensor([[0.2127, 0.4782],\n",
      "        [0.1912, 0.5824],\n",
      "        [0.2024, 0.4597],\n",
      "        [0.2000, 0.4939]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [15/1000], Loss: 0.2127\n",
      "tensor([[0.2176, 0.4799],\n",
      "        [0.2010, 0.5822],\n",
      "        [0.2102, 0.4690],\n",
      "        [0.2091, 0.4870]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [16/1000], Loss: 0.2102\n",
      "tensor([[0.2224, 0.4811],\n",
      "        [0.2102, 0.5813],\n",
      "        [0.2179, 0.4761],\n",
      "        [0.2177, 0.4792]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [17/1000], Loss: 0.2080\n",
      "tensor([[0.2270, 0.4819],\n",
      "        [0.2186, 0.5799],\n",
      "        [0.2250, 0.4797],\n",
      "        [0.2250, 0.4797]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [18/1000], Loss: 0.2075\n",
      "tensor([[0.2317, 0.4828],\n",
      "        [0.2263, 0.5809],\n",
      "        [0.2317, 0.4828],\n",
      "        [0.2317, 0.4828]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [19/1000], Loss: 0.2073\n",
      "tensor([[0.2380, 0.4854],\n",
      "        [0.2333, 0.5837],\n",
      "        [0.2380, 0.4854],\n",
      "        [0.2380, 0.4854]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [20/1000], Loss: 0.2072\n",
      "tensor([[0.2439, 0.4874],\n",
      "        [0.2396, 0.5882],\n",
      "        [0.2439, 0.4874],\n",
      "        [0.2439, 0.4874]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [21/1000], Loss: 0.2069\n",
      "tensor([[0.2493, 0.4888],\n",
      "        [0.2453, 0.5938],\n",
      "        [0.2493, 0.4888],\n",
      "        [0.2493, 0.4888]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [22/1000], Loss: 0.2065\n",
      "tensor([[0.2542, 0.4895],\n",
      "        [0.2505, 0.6004],\n",
      "        [0.2542, 0.4895],\n",
      "        [0.2542, 0.4895]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [23/1000], Loss: 0.2060\n",
      "tensor([[0.2587, 0.4895],\n",
      "        [0.2550, 0.6078],\n",
      "        [0.2587, 0.4895],\n",
      "        [0.2587, 0.4895]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [24/1000], Loss: 0.2053\n",
      "Early stopping triggered!\n",
      "tensor([[-0.1266, -0.1490],\n",
      "        [-0.1692, -0.2329],\n",
      "        [-0.1767, -0.4374],\n",
      "        [ 0.0529, -0.3697]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/1000], Loss: 0.5897\n",
      "tensor([[-0.0897, -0.0986],\n",
      "        [-0.1295, -0.1731],\n",
      "        [-0.1320, -0.3675],\n",
      "        [ 0.0819, -0.3149]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [2/1000], Loss: 0.5300\n",
      "tensor([[-0.0532, -0.0484],\n",
      "        [-0.0901, -0.1134],\n",
      "        [-0.0882, -0.2977],\n",
      "        [ 0.1101, -0.2601]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [3/1000], Loss: 0.4755\n",
      "tensor([[-0.0174,  0.0016],\n",
      "        [-0.0515, -0.0539],\n",
      "        [-0.0462, -0.2274],\n",
      "        [ 0.1369, -0.2048]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [4/1000], Loss: 0.4261\n",
      "tensor([[ 0.0170,  0.0512],\n",
      "        [-0.0141,  0.0057],\n",
      "        [-0.0066, -0.1567],\n",
      "        [ 0.1622, -0.1489]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [5/1000], Loss: 0.3817\n",
      "tensor([[ 0.0492,  0.1003],\n",
      "        [ 0.0215,  0.0651],\n",
      "        [ 0.0303, -0.0858],\n",
      "        [ 0.1864, -0.0925]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [6/1000], Loss: 0.3422\n",
      "tensor([[ 0.0782,  0.1489],\n",
      "        [ 0.0549,  0.1245],\n",
      "        [ 0.0637, -0.0149],\n",
      "        [ 0.2101, -0.0359]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [7/1000], Loss: 0.3071\n",
      "tensor([[0.1033, 0.1967],\n",
      "        [0.0859, 0.1834],\n",
      "        [0.0929, 0.0558],\n",
      "        [0.2336, 0.0205]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [8/1000], Loss: 0.2764\n",
      "tensor([[0.1246, 0.2436],\n",
      "        [0.1144, 0.2417],\n",
      "        [0.1178, 0.1261],\n",
      "        [0.2573, 0.0764]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [9/1000], Loss: 0.2497\n",
      "tensor([[0.1425, 0.2894],\n",
      "        [0.1408, 0.2990],\n",
      "        [0.1387, 0.1959],\n",
      "        [0.2814, 0.1315]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [10/1000], Loss: 0.2268\n",
      "tensor([[0.1566, 0.3353],\n",
      "        [0.1653, 0.3552],\n",
      "        [0.1560, 0.2649],\n",
      "        [0.3117, 0.1942]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [11/1000], Loss: 0.2070\n",
      "tensor([[0.1672, 0.3813],\n",
      "        [0.1882, 0.4099],\n",
      "        [0.1704, 0.3328],\n",
      "        [0.3434, 0.2577]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [12/1000], Loss: 0.1911\n",
      "tensor([[0.1755, 0.4255],\n",
      "        [0.2097, 0.4626],\n",
      "        [0.1821, 0.3991],\n",
      "        [0.3751, 0.3193]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [13/1000], Loss: 0.1789\n",
      "tensor([[0.1815, 0.4674],\n",
      "        [0.2296, 0.5126],\n",
      "        [0.1912, 0.4630],\n",
      "        [0.4066, 0.3781]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [14/1000], Loss: 0.1702\n",
      "tensor([[0.1852, 0.5065],\n",
      "        [0.2479, 0.5593],\n",
      "        [0.1976, 0.5237],\n",
      "        [0.4374, 0.4330]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [15/1000], Loss: 0.1645\n",
      "tensor([[0.1867, 0.5422],\n",
      "        [0.2646, 0.6015],\n",
      "        [0.2013, 0.5804],\n",
      "        [0.4675, 0.4827]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [16/1000], Loss: 0.1613\n",
      "tensor([[0.1860, 0.5738],\n",
      "        [0.2793, 0.6385],\n",
      "        [0.2023, 0.6319],\n",
      "        [0.4965, 0.5259]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [17/1000], Loss: 0.1599\n",
      "tensor([[0.1831, 0.6008],\n",
      "        [0.2919, 0.6694],\n",
      "        [0.2006, 0.6774],\n",
      "        [0.5241, 0.5616]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [18/1000], Loss: 0.1594\n",
      "Early stopping triggered!\n",
      "tensor([[-0.1664,  0.2130],\n",
      "        [-0.2086,  0.4410],\n",
      "        [-0.3963,  0.5809],\n",
      "        [-0.4555,  0.7814]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/1000], Loss: 0.4363\n",
      "tensor([[-0.1057,  0.1730],\n",
      "        [-0.1214,  0.3998],\n",
      "        [-0.3161,  0.5130],\n",
      "        [-0.3404,  0.6864]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [2/1000], Loss: 0.3776\n",
      "tensor([[-0.0481,  0.1647],\n",
      "        [-0.0367,  0.3897],\n",
      "        [-0.2372,  0.4893],\n",
      "        [-0.2274,  0.6360]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [3/1000], Loss: 0.3289\n",
      "tensor([[ 0.0063,  0.1708],\n",
      "        [ 0.0446,  0.3923],\n",
      "        [-0.1577,  0.4909],\n",
      "        [-0.1171,  0.6092]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [4/1000], Loss: 0.2879\n",
      "tensor([[ 0.0569,  0.1837],\n",
      "        [ 0.1211,  0.4015],\n",
      "        [-0.0791,  0.5034],\n",
      "        [-0.0100,  0.5957]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [5/1000], Loss: 0.2547\n",
      "tensor([[ 0.1022,  0.1994],\n",
      "        [ 0.1922,  0.4141],\n",
      "        [-0.0030,  0.5226],\n",
      "        [ 0.0931,  0.5905]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seu21\\anaconda3\\envs\\ai_lab\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([4, 2])) that is different to the input size (torch.Size([2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/1000], Loss: 0.2287\n",
      "tensor([[0.1414, 0.2164],\n",
      "        [0.2576, 0.4283],\n",
      "        [0.0696, 0.5455],\n",
      "        [0.1916, 0.5903]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [7/1000], Loss: 0.2092\n",
      "tensor([[0.1745, 0.2338],\n",
      "        [0.3163, 0.4449],\n",
      "        [0.1377, 0.5685],\n",
      "        [0.2840, 0.5927]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [8/1000], Loss: 0.1953\n",
      "tensor([[0.2008, 0.2501],\n",
      "        [0.3680, 0.4625],\n",
      "        [0.2004, 0.5911],\n",
      "        [0.3667, 0.5987]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [9/1000], Loss: 0.1868\n",
      "tensor([[0.2202, 0.2637],\n",
      "        [0.4126, 0.4776],\n",
      "        [0.2569, 0.6105],\n",
      "        [0.4418, 0.6014]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [10/1000], Loss: 0.1815\n",
      "tensor([[0.2326, 0.2730],\n",
      "        [0.4477, 0.4873],\n",
      "        [0.3062, 0.6245],\n",
      "        [0.5081, 0.5986]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [11/1000], Loss: 0.1784\n",
      "tensor([[0.2382, 0.2775],\n",
      "        [0.4754, 0.4933],\n",
      "        [0.3474, 0.6324],\n",
      "        [0.5648, 0.5894]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [12/1000], Loss: 0.1761\n",
      "Early stopping triggered!\n",
      "tensor([[0.1780, 0.6229],\n",
      "        [0.3023, 0.6940],\n",
      "        [0.1959, 0.7163],\n",
      "        [0.5498, 0.5892]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/1000], Loss: 0.1592\n",
      "tensor([[-0.1267, -0.1115],\n",
      "        [ 0.3554, -0.0747],\n",
      "        [ 0.0744, -0.2541],\n",
      "        [ 0.9256, -0.4625]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [2/1000], Loss: 0.3884\n",
      "tensor([[-0.6752,  0.3450],\n",
      "        [-0.4086,  0.5342],\n",
      "        [-0.6624,  0.5655],\n",
      "        [ 0.1042,  0.2029]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [3/1000], Loss: 0.3038\n",
      "tensor([[-0.2427,  0.6357],\n",
      "        [ 0.0578,  0.9628],\n",
      "        [-0.0891,  1.0753],\n",
      "        [ 0.7020,  0.5902]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [4/1000], Loss: 0.1148\n",
      "tensor([[0.1814, 0.6308],\n",
      "        [0.5768, 0.9674],\n",
      "        [0.4889, 1.1661],\n",
      "        [1.3465, 0.5241]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [5/1000], Loss: 0.1783\n",
      "tensor([[0.2927, 0.4732],\n",
      "        [0.6337, 0.8056],\n",
      "        [0.5590, 1.0602],\n",
      "        [1.3873, 0.3393]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [6/1000], Loss: 0.1663\n",
      "tensor([[0.2196, 0.2951],\n",
      "        [0.4358, 0.6373],\n",
      "        [0.3367, 0.9862],\n",
      "        [1.1373, 0.1670]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [7/1000], Loss: 0.0771\n",
      "tensor([[0.0918, 0.1560],\n",
      "        [0.1727, 0.5481],\n",
      "        [0.0138, 1.0129],\n",
      "        [0.8422, 0.0560]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [8/1000], Loss: 0.0369\n",
      "tensor([[-0.0222,  0.0641],\n",
      "        [-0.0595,  0.5461],\n",
      "        [-0.2619,  1.0805],\n",
      "        [ 0.6113, -0.0097]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [9/1000], Loss: 0.0551\n",
      "tensor([[-0.0908,  0.0099],\n",
      "        [-0.2187,  0.6135],\n",
      "        [-0.3503,  1.0830],\n",
      "        [ 0.4892, -0.0448]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [10/1000], Loss: 0.0748\n",
      "tensor([[-0.1119, -0.0175],\n",
      "        [-0.2951,  0.7318],\n",
      "        [-0.2742,  0.9875],\n",
      "        [ 0.4708, -0.0623]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [11/1000], Loss: 0.0664\n",
      "tensor([[-0.0902, -0.0250],\n",
      "        [-0.2934,  0.8836],\n",
      "        [-0.1031,  0.8651],\n",
      "        [ 0.5341, -0.0675]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [12/1000], Loss: 0.0449\n",
      "Early stopping triggered!\n"
     ]
    },
    {
     "data": {
      "text/plain": "RegressionModel(\n  (input): Linear(in_features=2, out_features=10, bias=True)\n  (activation): ReLU()\n  (output): Linear(in_features=10, out_features=2, bias=True)\n)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RegressionModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.input = torch.nn.Linear(input_dim, hidden_dim)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.output = torch.nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train_model(model, X_train, y_train, num_epochs=100, lr=0.01, patience=5):\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in range(num_epochs):\n",
    "        # Forward pass\n",
    "        outputs = model(X_train)\n",
    "        print(outputs)\n",
    "        loss = criterion(outputs, y_train)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs in X_train:\n",
    "                outputs = model(inputs)\n",
    "                val_loss += criterion(outputs, y_train).item()\n",
    "        val_loss /= len(X_train)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement >= patience:\n",
    "                print(\"Early stopping triggered!\")\n",
    "                break\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "X = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "y = torch.tensor([[0, 0], [0, 1], [0, 1], [1, 0]], dtype=torch.float32)\n",
    "model1 = RegressionModel(2, 2, 4)\n",
    "model1 = train_model(model1, X, y, num_epochs=1000, lr=0.01)\n",
    "model2 = RegressionModel(2, 2, 10)\n",
    "model2 = train_model(model2, X, y, num_epochs=1000, lr=0.01)\n",
    "model3 = RegressionModel(2, 2, 15)\n",
    "model3 = train_model(model3, X, y, num_epochs=1000, lr=0.01)\n",
    "train_model(model2, X, y, num_epochs=1000, lr=0.15)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
